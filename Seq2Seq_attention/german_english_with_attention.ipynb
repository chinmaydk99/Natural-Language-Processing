{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field,BucketIterator\n",
    "from torch.utils.tensorboard import SummaryWriter # To print to tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import translate_sentence, bleu,save_checkpoint,load_checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load('de_core_news_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ger_tokenizer(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def eng_tokenizer(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fields for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize= ger_tokenizer, sequential=True,lower = True,\n",
    "               init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "english = Field(tokenize= eng_tokenizer, sequential=True,lower = True,\n",
    "               init_token='<sos>', eos_token='<eos>')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 665kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 123kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 101kB/s] \n"
     ]
    }
   ],
   "source": [
    "train_data , valid_data , test_data = Multi30k.splits(exts=('.de','.en'),\n",
    "                                                      fields = (german,english))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size = 1000, min_freq = 2)\n",
    "english.build_vocab(train_data, max_size = 1000, min_freq = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size, embed_size,hidden_size,num_layers,p):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size,embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,num_layers,\n",
    "                            bidirectional = True)\n",
    "\n",
    "        # Since we use bidirectional LSTM , we will have forward and backward hidden and cell states\n",
    "        # Hence we feed both to the neural network and let it choose which one it'll assign importance and relay forward\n",
    "        self.fc_hidden = nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size*2,hidden_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x shape : (seq_length, batch_size)\n",
    "\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        # embedding shape : (seq_length, batch_size, embedding_size)\n",
    "\n",
    "        encoder_states , (hidden,cell) = self.lstm(embedded)\n",
    "        # outputs shape : (seq_length, batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate the forward and reverse hidden and cell states\n",
    "        # After concatenation shape will be(2,batch_size, hidden_size)\n",
    "        # We are concatenating along the hidden size dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1],hidden[1:2]),dim = 2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1],cell[1:2]),dim = 2))\n",
    "\n",
    "        return encoder_states, hidden,cell\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need for concatenation\n",
    "\n",
    "By using a bidirectional LSTM, the Encoder is able to capture information from both the past and future context of the input sequence. The forward LSTM processes the sequence in the original order, while the backward LSTM processes it in reverse order. By concatenating the hidden and cell states of both LSTMs, the Encoder captures information from both directions and provides a more comprehensive representation of the input sequence.\n",
    "\n",
    "#### Need for fc_out and fc_hidden\n",
    "\n",
    "They play a role in transforming the concatenated states to the desired dimensionality. They apply a linear transformation to the concatenated states, allowing the model to learn the appropriate weights for mapping the concatenated states to the hidden size. This helps in capturing the most relevant and useful information from the bidirectional states and providing a compact representation to be used by the decoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiddden and cell have shapes `(num_layers * num_directions, batch_size, hidden_size)` which is why the slicing works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "* Initialise parameters\n",
    "* lstm input dimension will be `hidden_size*2+embedding_size` since the input will be a concatenation of context vector and previously generated word(embedded representation)\n",
    "* Energy - used to obtain scores for the encoder states is initialised to a dimension of `hidden_size*3,1` since we feed the hidden states of encoder plus the previous hidden state of the decoder\n",
    "* A softmax layer is used to obtain the attention weights\n",
    "\n",
    "* We obtain the `sequence_length` of the encoder states. The decoder initial hidden state is repeated `sequence_length` times so that the shape matches with encoder states and the decoder has access to the same initial hidden state for every time step during decoding.\n",
    "* The hidden state and encoder states are concatenated along the hidden_size*2 dimension and passed through a neural network followed by RELU\n",
    "* The output thus obtained is passed through softmax layer to obtain the attention weights\n",
    "* The shapes of the attention weights and the encoder states are adjusted using `permute` so that elementwise multiplication can be carried out and context vectors can be obtained\n",
    "* The context vectors are concatenated with the previous word generated and passed on to the lstm following which it is passed through feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,embedding_size, hidden_size,output_size,num_layers,p):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size,embedding_size)\n",
    "\n",
    "        # Since we will be concatenating the previously generated word and the context vectors\n",
    "        self.lstm = nn.LSTM(self.hidden_size*2 + embedding_size, hidden_size,num_layers)\n",
    "\n",
    "        # Since we have the hidden states from the encoder plus the previous hidden state of the decoder\n",
    "        self.energy = nn.Linear(hidden_size*3,1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x,encoder_states,hidden,cell):\n",
    "        # x ha shape (N) we want it (1,N) since we are sening a single word\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape (1,batch_size,embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        # Repeating hidden state to match the shape of encoder_states\n",
    "        h_reshaped = hidden.repeat(sequence_length,1,1)\n",
    "        # h_reshaped :(seq_length,N,hidden_size*2)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        # Concatenate the hidden decoder states and the encoder states along the hidden_size*2 dimension\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped,encoder_states), dim = 2)))\n",
    "        # energy : (seq_length,N,1)\n",
    "\n",
    "        # Obtain the attention weights\n",
    "        attention = self.softmax(energy)\n",
    "        \n",
    "        # Alter the shapes so that elementwise multiplication can be carried out\n",
    "        # (seq_length,N,1) --> (N,1,seq_length)\n",
    "        attention = attention.permute(1,2,0)\n",
    "        \n",
    "        # (seq_length,N,hidden_size*2) --> (N,seq_length_hidden_size*2)\n",
    "        encoder_states = encoder_states.permute(1,0,2)\n",
    "        \n",
    "        # Obtain context vector by carrying out elementwise multiplication of attention weights and encoder states\n",
    "        context_vector = torch.bmm(attention,encoder_states).permute(1,0,2)\n",
    "        # (N,1,hidden_size*2) --> (1,N,hidden_size*2)\n",
    "\n",
    "        # Input to decoder is obtained by concatenating context vector with embedded input sequence\n",
    "        rnn_input = torch.cat((context_vector,embedding),dim=2)\n",
    "        # rnn input : (1,N,hidden_size *2 + embedding_size\n",
    "\n",
    "        outputs, (hidden,cell) = self.lstm(rnn_input,(hidden,cell))\n",
    "        # output shape : (1,N,hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs) \n",
    "\n",
    "        # (1,N,len_target_vocab) --> (N,len_target_vocab)\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target , teacher_force_ratio = 0.5):\n",
    "        # Torch tensors usually have shape (sequence_length, batch_size)\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "\n",
    "        len_target_vocab = len(english.vocab)\n",
    "\n",
    "        # Decoder o/p has shape (batch_size,target_vocab_len) which are accumulated over target_len number of words\n",
    "        outputs = torch.zeros(target_len,batch_size, len_target_vocab)\n",
    "\n",
    "        # Obtain the encoder states \n",
    "        encoder_states , hidden,cell = self.encoder(source)\n",
    "\n",
    "        # Grab the start token\n",
    "\n",
    "        x= target[0]\n",
    "\n",
    "        for t in range(1,target_len):\n",
    "            output, hidden ,cell = self.decoder(x,encoder_states,hidden,cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Output has shape (batch_size, vocab_size)\n",
    "            # So argmax along 1st dimension would  yield the word with the highest probability\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # Whether to use true label or previous output for training\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "            return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "batch_size = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise iterators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance of `sort_within_batch`\n",
    "- This makes sure that examples with similar sequence lengths are grouped together in a batch so that the need for padding is reduced and computation becomes more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data,valid_data,test_data),\n",
    "    batch_size = batch_size,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x : len(x.src),\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_layers,enc_dropout).to(device)\n",
    "decoder_net = Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size, num_layers,dec_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net,decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss with modification to ignore padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Courses\\Natural Language Processing\\Deep_Learning_Techniques\\Seq2Seq_attention\\german_english_with_attention.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# save_checkpoint(checkpoint)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     translated_sentence \u001b[39m=\u001b[39m translate_sentence(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         model,sentence,german,english,device,max_length\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTranslated example sentence : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtranslated_sentence\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Courses/Natural%20Language%20Processing/Deep_Learning_Techniques/Seq2Seq_attention/german_english_with_attention.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx,batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_iterator):\n",
      "File \u001b[1;32md:\\Courses\\Natural Language Processing\\Deep_Learning_Techniques\\Seq2Seq_attention\\utils.py:36\u001b[0m, in \u001b[0;36mtranslate_sentence\u001b[1;34m(model, sentence, german, english, device, max_length)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# Build encoder hidden, cell state\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 36\u001b[0m     hidden, cell \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencoder(sentence_tensor)\n\u001b[0;32m     38\u001b[0m outputs \u001b[39m=\u001b[39m [english\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_length):\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "\n",
    "    # checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\n",
    "    # save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model,sentence,german,english,device,max_length=50\n",
    "    )\n",
    "\n",
    "    print(f'Translated example sentence : \\n{translated_sentence}')\n",
    "\n",
    "    for batch_idx,batch in enumerate(train_iterator):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        output = model(inp_data,target)\n",
    "        # The output has shape (target_len,batch_size,output_size)\n",
    "        # But cross entropy function expects data in a particular dimension for which we squash together the first two dimensions\n",
    "\n",
    "        # We won't be sending 'start of sentence' token to the decoder hence we consider from index 1 onwards\n",
    "        output = output[1:].reshape(-1,output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output,target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping to avoid exploding gradient problem'\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('Training Loss',loss,global_step=step)\n",
    "        step += 1\n",
    "    \n",
    "    print(f'Epoch {epoch+1} / {num_epochs} Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
